{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22ffb9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import logging\n",
    "import numpy as np\n",
    "import pywt\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "import multiprocessing\n",
    "\n",
    "# Suppress TensorFlow INFO and WARNING logs, and disable oneDNN optimizations (optional)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define directories\n",
    "DATA_ROOT = \"data\"  # Folder with sub-folders for each state\n",
    "MODEL_SAVE_DIR = \"models\"\n",
    "if not os.path.exists(MODEL_SAVE_DIR):\n",
    "    os.makedirs(MODEL_SAVE_DIR)\n",
    "MODEL_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, \"structural_state_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "718462dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label mapping for each state folder\n",
    "state_labels = {\n",
    "    \"state#01\": {\"label\": \"Mass on the 1st floor\", \"samples\": list(range(11, 21))},\n",
    "    \"state#02\": {\"label\": \"Mass at the base\", \"samples\": list(range(21, 31))},\n",
    "    \"state#08\": {\"label\": \"Gap=0.13mm\", \"samples\": list(range(160, 170))},\n",
    "    \"state#09\": {\"label\": \"Gap=0.10mm\", \"samples\": list(range(170, 180))},\n",
    "    \"state#10\": {\"label\": \"Gap=0.05mm\", \"samples\": list(range(180, 190))},\n",
    "    \"state#11\": {\"label\": \"Gap=0.15mm\", \"samples\": list(range(190, 200))},\n",
    "    \"state#12\": {\"label\": \"Gap=0.20mm\", \"samples\": list(range(200, 210))},\n",
    "    \"state#13\": {\"label\": \"Baseline condition\", \"samples\": list(range(210, 220))},\n",
    "    \"state#14\": {\"label\": \"Gap=0.20mm + mass on the 1st floor\", \"samples\": list(range(220, 230))},\n",
    "    \"state#15\": {\"label\": \"Gap=0.10mm + mass on the 1st floor\", \"samples\": list(range(230, 240))},\n",
    "    \"state#16\": {\"label\": \"Gap=0.20mm + mass at the base\", \"samples\": list(range(240, 250))},\n",
    "    \"state#17\": {\"label\": \"Column: 1BD – 50% stiffness reduction\", \"samples\": list(range(251, 261))},\n",
    "    \"state#18\": {\"label\": \"Column: 1AD + 1BD – 50% stiffness reduction\", \"samples\": list(range(261, 271))},\n",
    "    \"state#21\": {\"label\": \"Column: 3BD – 50% stiffness reduction\", \"samples\": list(range(291, 301))},\n",
    "    \"state#22\": {\"label\": \"Column: 3AD + 3BD – 50% stiffness reduction\", \"samples\": list(range(302, 312))},\n",
    "    \"state#23\": {\"label\": \"Column: 2AD + 2BD – 50% stiffness reduction\", \"samples\": list(range(312, 322))},\n",
    "    \"state#24\": {\"label\": \"Column: 2BD – 50% stiffness reduction\", \"samples\": list(range(322, 332))}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0f49542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_root=DATA_ROOT):\n",
    "    \"\"\"\n",
    "    Loads 1D sensor signal text files from sub-folders in the data_root.\n",
    "    Filters files based on the sample number parsed from the filename.\n",
    "    \"\"\"\n",
    "    data_samples = []\n",
    "    labels = []\n",
    "    for state_folder in os.listdir(data_root):\n",
    "        folder_path = os.path.join(data_root, state_folder)\n",
    "        if os.path.isdir(folder_path) and state_folder in state_labels:\n",
    "            mapping = state_labels[state_folder]\n",
    "            sample_range = mapping[\"samples\"]\n",
    "            label_str = mapping[\"label\"]\n",
    "            logging.info(f\"Processing folder '{state_folder}' with sample range {sample_range} and label: {label_str}\")\n",
    "            file_pattern = os.path.join(folder_path, \"data*.txt\")\n",
    "            for file_path in glob.glob(file_pattern):\n",
    "                filename = os.path.basename(file_path)\n",
    "                sample_num_str = \"\".join(filter(str.isdigit, filename))\n",
    "                try:\n",
    "                    sample_num = int(sample_num_str)\n",
    "                except ValueError:\n",
    "                    logging.warning(f\"Could not parse sample number from {filename}\")\n",
    "                    continue\n",
    "                if sample_num in sample_range:\n",
    "                    try:\n",
    "                        data_array = np.loadtxt(file_path)\n",
    "                        data_samples.append(data_array)\n",
    "                        labels.append(label_str)\n",
    "                        logging.info(f\"Loaded {file_path} with label: {label_str}\")\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Error loading {file_path}: {e}\")\n",
    "                        continue\n",
    "    if len(data_samples) == 0 or len(labels) == 0:\n",
    "        raise ValueError(\"No data was loaded. Verify your folder structure and file naming.\")\n",
    "    return np.array(data_samples), np.array(labels)\n",
    "\n",
    "def preprocess_signal_data(data_samples, data_labels):\n",
    "    \"\"\"\n",
    "    Encodes labels and scales the 1D sensor signals.\n",
    "    Returns the processed signals, one-hot labels, and the encoders/scalers.\n",
    "    \"\"\"\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(data_labels)\n",
    "    logging.info(\"Encoded label mapping: %s\",\n",
    "                 dict(zip(label_encoder.classes_,\n",
    "                          label_encoder.transform(label_encoder.classes_))))\n",
    "    onehot_labels = to_categorical(encoded_labels)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    data_samples_stacked = np.vstack(data_samples)\n",
    "    data_samples_scaled = scaler.fit_transform(data_samples_stacked)\n",
    "    # Restore individual samples\n",
    "    data_samples_processed = []\n",
    "    idx = 0\n",
    "    for sample in data_samples:\n",
    "        length = sample.shape[0]\n",
    "        data_samples_processed.append(data_samples_scaled[idx:idx+length])\n",
    "        idx += length\n",
    "    data_samples_processed = np.array(data_samples_processed)\n",
    "    return data_samples_processed, onehot_labels, label_encoder, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62b1aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cwt_image(signal, scales=None, wavelet_name='morl', output_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Computes the Continuous Wavelet Transform (CWT) of a 1D signal and returns a 2D grayscale image.\n",
    "    The output image will have shape: (output_size[0], output_size[1], 1)\n",
    "    \"\"\"\n",
    "    if scales is None:\n",
    "        scales = np.arange(1, min(129, len(signal) + 1))\n",
    "    \n",
    "    coefficients, _ = pywt.cwt(signal, scales, wavelet_name)\n",
    "    coeff_min, coeff_max = np.min(coefficients), np.max(coefficients)\n",
    "    if coeff_max != coeff_min:\n",
    "        coeff_norm = (coefficients - coeff_min) / (coeff_max - coeff_min)\n",
    "    else:\n",
    "        coeff_norm = coefficients\n",
    "    coeff_image = (coeff_norm * 255).astype(np.uint8)\n",
    "    \n",
    "    # Remove singleton dimensions.\n",
    "    coeff_image = np.squeeze(coeff_image)\n",
    "    \n",
    "    # Force to 2D: if 1D, expand dims; if >2D, reshape to (rows, -1).\n",
    "    if coeff_image.ndim == 1:\n",
    "        coeff_image = np.expand_dims(coeff_image, axis=0)\n",
    "    elif coeff_image.ndim > 2:\n",
    "        coeff_image = coeff_image.reshape(coeff_image.shape[0], -1)\n",
    "    \n",
    "    try:\n",
    "        img = Image.fromarray(coeff_image)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting coefficient array to image: {e}\")\n",
    "        raise e\n",
    "    \n",
    "    img = img.resize(output_size, resample=Image.BILINEAR)\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Ensure the image has shape (H, W, 1) if it's grayscale.\n",
    "    if img_array.ndim == 2:\n",
    "        img_array = np.expand_dims(img_array, axis=-1)\n",
    "    \n",
    "    # Optional: Check if the shape is correct and print a warning if not.\n",
    "    if img_array.shape != (output_size[0], output_size[1], 1):\n",
    "        logging.warning(f\"Expected shape {(output_size[0], output_size[1], 1)} but got {img_array.shape}\")\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "\n",
    "# Needed for parallel processing\n",
    "def process_sample(sample):\n",
    "    return compute_cwt_image(sample)\n",
    "\n",
    "def create_image_dataset_parallel(signal_data, num_workers=None):\n",
    "    \"\"\"\n",
    "    Converts all 1D sensor signals to 224x224 time-frequency images using CWT in parallel.\n",
    "    Returns a numpy array with shape: (num_samples, 224, 224, 1)\n",
    "    \"\"\"\n",
    "    import multiprocessing\n",
    "    from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "    \n",
    "    logging.info(f\"Starting parallel conversion with {num_workers or os.cpu_count()} workers...\")\n",
    "    images = []  # Use a list to collect image arrays\n",
    "    \n",
    "    # Create a ProcessPoolExecutor with a 'spawn' context for notebooks.\n",
    "    ctx = multiprocessing.get_context('spawn')\n",
    "    with ProcessPoolExecutor(max_workers=num_workers, mp_context=ctx) as executor:\n",
    "        futures = {executor.submit(process_sample, signal): i for i, signal in enumerate(signal_data)}\n",
    "        for future in tqdm(as_completed(futures), total=len(signal_data), desc=\"Converting signals\"):\n",
    "            idx = futures[future]\n",
    "            try:\n",
    "                img = future.result()\n",
    "                images.append(img)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing signal index {idx}: {e}\")\n",
    "    \n",
    "    # Combine individual image arrays into one array.\n",
    "    images = np.stack(images)\n",
    "    logging.info(f\"Converted {images.shape[0]} samples to images (parallelized).\")\n",
    "    return images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa3b1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dcnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Builds the DCNN model architecture for CWT images.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)  # e.g., (224, 224, 1)\n",
    "    \n",
    "    # Convolution Block 1\n",
    "    x = Conv2D(96, kernel_size=(7, 7), strides=(2, 2), padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    \n",
    "    # Convolution Block 2\n",
    "    x = Conv2D(256, kernel_size=(5, 5), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    \n",
    "    # Convolution Blocks 3, 4 and 5 using 3x3 kernels\n",
    "    x = Conv2D(384, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    \n",
    "    # Fully Connected Layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Improved optimizer parameters and compilation\n",
    "    optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary(print_fn=logging.info)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bb77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loading data...\n",
      "INFO: Processing folder 'state#01' with sample range [11, 12, 13, 14, 15, 16, 17, 18, 19, 20] and label: Mass on the 1st floor\n",
      "INFO: Loaded data\\state#01\\data11.txt with label: Mass on the 1st floor\n",
      "INFO: Loaded data\\state#01\\data12.txt with label: Mass on the 1st floor\n",
      "INFO: Loaded data\\state#01\\data13.txt with label: Mass on the 1st floor\n",
      "INFO: Loaded data\\state#01\\data14.txt with label: Mass on the 1st floor\n",
      "INFO: Loaded data\\state#01\\data15.txt with label: Mass on the 1st floor\n",
      "INFO: Loaded data\\state#01\\data16.txt with label: Mass on the 1st floor\n",
      "INFO: Loaded data\\state#01\\data17.txt with label: Mass on the 1st floor\n",
      "INFO: Loaded data\\state#01\\data18.txt with label: Mass on the 1st floor\n",
      "INFO: Loaded data\\state#01\\data19.txt with label: Mass on the 1st floor\n",
      "INFO: Loaded data\\state#01\\data20.txt with label: Mass on the 1st floor\n",
      "INFO: Processing folder 'state#02' with sample range [21, 22, 23, 24, 25, 26, 27, 28, 29, 30] and label: Mass at the base\n",
      "INFO: Loaded data\\state#02\\data21.txt with label: Mass at the base\n",
      "INFO: Loaded data\\state#02\\data22.txt with label: Mass at the base\n",
      "INFO: Loaded data\\state#02\\data23.txt with label: Mass at the base\n",
      "INFO: Loaded data\\state#02\\data24.txt with label: Mass at the base\n",
      "INFO: Loaded data\\state#02\\data25.txt with label: Mass at the base\n",
      "INFO: Loaded data\\state#02\\data26.txt with label: Mass at the base\n",
      "INFO: Loaded data\\state#02\\data27.txt with label: Mass at the base\n",
      "INFO: Loaded data\\state#02\\data28.txt with label: Mass at the base\n",
      "INFO: Loaded data\\state#02\\data29.txt with label: Mass at the base\n",
      "INFO: Loaded data\\state#02\\data30.txt with label: Mass at the base\n",
      "INFO: Processing folder 'state#08' with sample range [160, 161, 162, 163, 164, 165, 166, 167, 168, 169] and label: Gap=0.13mm\n",
      "INFO: Loaded data\\state#08\\data160.txt with label: Gap=0.13mm\n",
      "INFO: Loaded data\\state#08\\data161.txt with label: Gap=0.13mm\n",
      "INFO: Loaded data\\state#08\\data162.txt with label: Gap=0.13mm\n",
      "INFO: Loaded data\\state#08\\data163.txt with label: Gap=0.13mm\n",
      "INFO: Loaded data\\state#08\\data164.txt with label: Gap=0.13mm\n",
      "INFO: Loaded data\\state#08\\data165.txt with label: Gap=0.13mm\n",
      "INFO: Loaded data\\state#08\\data166.txt with label: Gap=0.13mm\n",
      "INFO: Loaded data\\state#08\\data167.txt with label: Gap=0.13mm\n",
      "INFO: Loaded data\\state#08\\data168.txt with label: Gap=0.13mm\n",
      "INFO: Loaded data\\state#08\\data169.txt with label: Gap=0.13mm\n",
      "INFO: Processing folder 'state#09' with sample range [170, 171, 172, 173, 174, 175, 176, 177, 178, 179] and label: Gap=0.10mm\n",
      "INFO: Loaded data\\state#09\\data170.txt with label: Gap=0.10mm\n",
      "INFO: Loaded data\\state#09\\data171.txt with label: Gap=0.10mm\n",
      "INFO: Loaded data\\state#09\\data172.txt with label: Gap=0.10mm\n",
      "INFO: Loaded data\\state#09\\data173.txt with label: Gap=0.10mm\n",
      "INFO: Loaded data\\state#09\\data174.txt with label: Gap=0.10mm\n",
      "INFO: Loaded data\\state#09\\data175.txt with label: Gap=0.10mm\n",
      "INFO: Loaded data\\state#09\\data176.txt with label: Gap=0.10mm\n",
      "INFO: Loaded data\\state#09\\data177.txt with label: Gap=0.10mm\n",
      "INFO: Loaded data\\state#09\\data178.txt with label: Gap=0.10mm\n",
      "INFO: Loaded data\\state#09\\data179.txt with label: Gap=0.10mm\n",
      "INFO: Processing folder 'state#10' with sample range [180, 181, 182, 183, 184, 185, 186, 187, 188, 189] and label: Gap=0.05mm\n",
      "INFO: Loaded data\\state#10\\data180.txt with label: Gap=0.05mm\n",
      "INFO: Loaded data\\state#10\\data181.txt with label: Gap=0.05mm\n",
      "INFO: Loaded data\\state#10\\data182.txt with label: Gap=0.05mm\n",
      "INFO: Loaded data\\state#10\\data183.txt with label: Gap=0.05mm\n",
      "INFO: Loaded data\\state#10\\data184.txt with label: Gap=0.05mm\n",
      "INFO: Loaded data\\state#10\\data185.txt with label: Gap=0.05mm\n",
      "INFO: Loaded data\\state#10\\data186.txt with label: Gap=0.05mm\n",
      "INFO: Loaded data\\state#10\\data187.txt with label: Gap=0.05mm\n",
      "INFO: Loaded data\\state#10\\data188.txt with label: Gap=0.05mm\n",
      "INFO: Loaded data\\state#10\\data189.txt with label: Gap=0.05mm\n",
      "INFO: Processing folder 'state#11' with sample range [190, 191, 192, 193, 194, 195, 196, 197, 198, 199] and label: Gap=0.15mm\n",
      "INFO: Loaded data\\state#11\\data190.txt with label: Gap=0.15mm\n",
      "INFO: Loaded data\\state#11\\data191.txt with label: Gap=0.15mm\n",
      "INFO: Loaded data\\state#11\\data192.txt with label: Gap=0.15mm\n",
      "INFO: Loaded data\\state#11\\data193.txt with label: Gap=0.15mm\n",
      "INFO: Loaded data\\state#11\\data194.txt with label: Gap=0.15mm\n",
      "INFO: Loaded data\\state#11\\data195.txt with label: Gap=0.15mm\n",
      "INFO: Loaded data\\state#11\\data196.txt with label: Gap=0.15mm\n",
      "INFO: Loaded data\\state#11\\data197.txt with label: Gap=0.15mm\n",
      "INFO: Loaded data\\state#11\\data198.txt with label: Gap=0.15mm\n",
      "INFO: Loaded data\\state#11\\data199.txt with label: Gap=0.15mm\n",
      "INFO: Processing folder 'state#12' with sample range [200, 201, 202, 203, 204, 205, 206, 207, 208, 209] and label: Gap=0.20mm\n",
      "INFO: Loaded data\\state#12\\data200.txt with label: Gap=0.20mm\n",
      "INFO: Loaded data\\state#12\\data201.txt with label: Gap=0.20mm\n",
      "INFO: Loaded data\\state#12\\data202.txt with label: Gap=0.20mm\n",
      "INFO: Loaded data\\state#12\\data203.txt with label: Gap=0.20mm\n",
      "INFO: Loaded data\\state#12\\data204.txt with label: Gap=0.20mm\n",
      "INFO: Loaded data\\state#12\\data205.txt with label: Gap=0.20mm\n",
      "INFO: Loaded data\\state#12\\data206.txt with label: Gap=0.20mm\n",
      "INFO: Loaded data\\state#12\\data207.txt with label: Gap=0.20mm\n",
      "INFO: Loaded data\\state#12\\data208.txt with label: Gap=0.20mm\n",
      "INFO: Loaded data\\state#12\\data209.txt with label: Gap=0.20mm\n",
      "INFO: Processing folder 'state#13' with sample range [210, 211, 212, 213, 214, 215, 216, 217, 218, 219] and label: Baseline condition\n",
      "INFO: Loaded data\\state#13\\data210.txt with label: Baseline condition\n",
      "INFO: Loaded data\\state#13\\data211.txt with label: Baseline condition\n",
      "INFO: Loaded data\\state#13\\data212.txt with label: Baseline condition\n",
      "INFO: Loaded data\\state#13\\data213.txt with label: Baseline condition\n",
      "INFO: Loaded data\\state#13\\data214.txt with label: Baseline condition\n",
      "INFO: Loaded data\\state#13\\data215.txt with label: Baseline condition\n",
      "INFO: Loaded data\\state#13\\data216.txt with label: Baseline condition\n",
      "INFO: Loaded data\\state#13\\data218.txt with label: Baseline condition\n",
      "INFO: Loaded data\\state#13\\data219.txt with label: Baseline condition\n",
      "INFO: Processing folder 'state#14' with sample range [220, 221, 222, 223, 224, 225, 226, 227, 228, 229] and label: Gap=0.20mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#14\\data220.txt with label: Gap=0.20mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#14\\data221.txt with label: Gap=0.20mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#14\\data222.txt with label: Gap=0.20mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#14\\data223.txt with label: Gap=0.20mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#14\\data224.txt with label: Gap=0.20mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#14\\data225.txt with label: Gap=0.20mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#14\\data226.txt with label: Gap=0.20mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#14\\data227.txt with label: Gap=0.20mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#14\\data228.txt with label: Gap=0.20mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#14\\data229.txt with label: Gap=0.20mm + mass on the 1st floor\n",
      "INFO: Processing folder 'state#15' with sample range [230, 231, 232, 233, 234, 235, 236, 237, 238, 239] and label: Gap=0.10mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#15\\data230.txt with label: Gap=0.10mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#15\\data231.txt with label: Gap=0.10mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#15\\data232.txt with label: Gap=0.10mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#15\\data233.txt with label: Gap=0.10mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#15\\data234.txt with label: Gap=0.10mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#15\\data235.txt with label: Gap=0.10mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#15\\data236.txt with label: Gap=0.10mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#15\\data237.txt with label: Gap=0.10mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#15\\data238.txt with label: Gap=0.10mm + mass on the 1st floor\n",
      "INFO: Loaded data\\state#15\\data239.txt with label: Gap=0.10mm + mass on the 1st floor\n",
      "INFO: Processing folder 'state#16' with sample range [240, 241, 242, 243, 244, 245, 246, 247, 248, 249] and label: Gap=0.20mm + mass at the base\n",
      "INFO: Loaded data\\state#16\\data240.txt with label: Gap=0.20mm + mass at the base\n",
      "INFO: Loaded data\\state#16\\data241.txt with label: Gap=0.20mm + mass at the base\n",
      "INFO: Loaded data\\state#16\\data242.txt with label: Gap=0.20mm + mass at the base\n",
      "INFO: Loaded data\\state#16\\data243.txt with label: Gap=0.20mm + mass at the base\n",
      "INFO: Loaded data\\state#16\\data244.txt with label: Gap=0.20mm + mass at the base\n",
      "INFO: Loaded data\\state#16\\data245.txt with label: Gap=0.20mm + mass at the base\n",
      "INFO: Loaded data\\state#16\\data246.txt with label: Gap=0.20mm + mass at the base\n",
      "INFO: Loaded data\\state#16\\data247.txt with label: Gap=0.20mm + mass at the base\n",
      "INFO: Loaded data\\state#16\\data248.txt with label: Gap=0.20mm + mass at the base\n",
      "INFO: Loaded data\\state#16\\data249.txt with label: Gap=0.20mm + mass at the base\n",
      "INFO: Processing folder 'state#17' with sample range [251, 252, 253, 254, 255, 256, 257, 258, 259, 260] and label: Column: 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#17\\data251.txt with label: Column: 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#17\\data252.txt with label: Column: 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#17\\data253.txt with label: Column: 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#17\\data254.txt with label: Column: 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#17\\data255.txt with label: Column: 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#17\\data256.txt with label: Column: 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#17\\data257.txt with label: Column: 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#17\\data258.txt with label: Column: 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#17\\data259.txt with label: Column: 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#17\\data260.txt with label: Column: 1BD – 50% stiffness reduction\n",
      "INFO: Processing folder 'state#18' with sample range [261, 262, 263, 264, 265, 266, 267, 268, 269, 270] and label: Column: 1AD + 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#18\\data261.txt with label: Column: 1AD + 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#18\\data262.txt with label: Column: 1AD + 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#18\\data263.txt with label: Column: 1AD + 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#18\\data264.txt with label: Column: 1AD + 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#18\\data265.txt with label: Column: 1AD + 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#18\\data266.txt with label: Column: 1AD + 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#18\\data267.txt with label: Column: 1AD + 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#18\\data268.txt with label: Column: 1AD + 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#18\\data269.txt with label: Column: 1AD + 1BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#18\\data270.txt with label: Column: 1AD + 1BD – 50% stiffness reduction\n",
      "INFO: Processing folder 'state#21' with sample range [291, 292, 293, 294, 295, 296, 297, 298, 299, 300] and label: Column: 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#21\\data291.txt with label: Column: 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#21\\data292.txt with label: Column: 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#21\\data293.txt with label: Column: 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#21\\data294.txt with label: Column: 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#21\\data295.txt with label: Column: 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#21\\data296.txt with label: Column: 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#21\\data297.txt with label: Column: 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#21\\data298.txt with label: Column: 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#21\\data299.txt with label: Column: 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#21\\data300.txt with label: Column: 3BD – 50% stiffness reduction\n",
      "INFO: Processing folder 'state#22' with sample range [302, 303, 304, 305, 306, 307, 308, 309, 310, 311] and label: Column: 3AD + 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#22\\data302.txt with label: Column: 3AD + 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#22\\data303.txt with label: Column: 3AD + 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#22\\data304.txt with label: Column: 3AD + 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#22\\data305.txt with label: Column: 3AD + 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#22\\data306.txt with label: Column: 3AD + 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#22\\data307.txt with label: Column: 3AD + 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#22\\data308.txt with label: Column: 3AD + 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#22\\data309.txt with label: Column: 3AD + 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#22\\data310.txt with label: Column: 3AD + 3BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#22\\data311.txt with label: Column: 3AD + 3BD – 50% stiffness reduction\n",
      "INFO: Processing folder 'state#23' with sample range [312, 313, 314, 315, 316, 317, 318, 319, 320, 321] and label: Column: 2AD + 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#23\\data312.txt with label: Column: 2AD + 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#23\\data313.txt with label: Column: 2AD + 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#23\\data314.txt with label: Column: 2AD + 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#23\\data315.txt with label: Column: 2AD + 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#23\\data316.txt with label: Column: 2AD + 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#23\\data317.txt with label: Column: 2AD + 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#23\\data318.txt with label: Column: 2AD + 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#23\\data319.txt with label: Column: 2AD + 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#23\\data320.txt with label: Column: 2AD + 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#23\\data321.txt with label: Column: 2AD + 2BD – 50% stiffness reduction\n",
      "INFO: Processing folder 'state#24' with sample range [322, 323, 324, 325, 326, 327, 328, 329, 330, 331] and label: Column: 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#24\\data322.txt with label: Column: 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#24\\data323.txt with label: Column: 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#24\\data324.txt with label: Column: 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#24\\data325.txt with label: Column: 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#24\\data326.txt with label: Column: 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#24\\data327.txt with label: Column: 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#24\\data328.txt with label: Column: 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#24\\data329.txt with label: Column: 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#24\\data330.txt with label: Column: 2BD – 50% stiffness reduction\n",
      "INFO: Loaded data\\state#24\\data331.txt with label: Column: 2BD – 50% stiffness reduction\n",
      "INFO: Preprocessing signal data...\n",
      "INFO: Encoded label mapping: {np.str_('Baseline condition'): np.int64(0), np.str_('Column: 1AD + 1BD – 50% stiffness reduction'): np.int64(1), np.str_('Column: 1BD – 50% stiffness reduction'): np.int64(2), np.str_('Column: 2AD + 2BD – 50% stiffness reduction'): np.int64(3), np.str_('Column: 2BD – 50% stiffness reduction'): np.int64(4), np.str_('Column: 3AD + 3BD – 50% stiffness reduction'): np.int64(5), np.str_('Column: 3BD – 50% stiffness reduction'): np.int64(6), np.str_('Gap=0.05mm'): np.int64(7), np.str_('Gap=0.10mm'): np.int64(8), np.str_('Gap=0.10mm + mass on the 1st floor'): np.int64(9), np.str_('Gap=0.13mm'): np.int64(10), np.str_('Gap=0.15mm'): np.int64(11), np.str_('Gap=0.20mm'): np.int64(12), np.str_('Gap=0.20mm + mass at the base'): np.int64(13), np.str_('Gap=0.20mm + mass on the 1st floor'): np.int64(14), np.str_('Mass at the base'): np.int64(15), np.str_('Mass on the 1st floor'): np.int64(16)}\n",
      "INFO: Converting training signals to time-frequency images using CWT in parallel...\n",
      "INFO: Starting parallel conversion with 16 workers...\n",
      "Converting signals:   0%|          | 0/135 [00:00<?, ?it/s]ERROR: Error processing signal index 0: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Converting signals:   1%|          | 1/135 [00:00<00:59,  2.27it/s]ERROR: Error processing signal index 1: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 2: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 3: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 4: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 5: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 6: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 7: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 8: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 9: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 10: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 11: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 12: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 13: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 14: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 15: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 16: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 17: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 18: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 19: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 20: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 21: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 22: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 23: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 24: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 25: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 26: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 27: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 28: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 29: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 30: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 31: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 32: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 33: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 34: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 35: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 36: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 37: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 38: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 39: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 40: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 41: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 42: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 43: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 44: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 45: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 46: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 47: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 48: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 49: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 50: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 51: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 52: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 53: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 54: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 55: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 56: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 57: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 58: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 59: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 60: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 61: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 62: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 63: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 64: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 65: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 66: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 67: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 68: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 69: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 70: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 71: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 72: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 73: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Converting signals:  55%|█████▍    | 74/135 [00:00<00:00, 179.86it/s]ERROR: Error processing signal index 74: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 75: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 76: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 77: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 78: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 79: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 80: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 81: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 82: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 83: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 84: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 85: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 86: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 87: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 88: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 89: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 90: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 91: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 92: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 93: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 94: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 95: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 96: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 97: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 98: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 99: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 100: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 101: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 102: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 103: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 104: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 105: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 106: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 107: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 108: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 109: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 110: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 111: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 112: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 113: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 114: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 115: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 116: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 117: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 118: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 119: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 120: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 121: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 122: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 123: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 124: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 125: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 126: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 127: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 128: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 129: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 130: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 131: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 132: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 133: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "ERROR: Error processing signal index 134: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Converting signals: 100%|██████████| 135/135 [00:00<00:00, 211.53it/s]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load raw 1D sensor signal data and labels\n",
    "    logging.info(\"Loading data...\")\n",
    "    signals, labels = load_data(DATA_ROOT)\n",
    "    \n",
    "    # Preprocess the raw 1D signals (scaling and label encoding)\n",
    "    logging.info(\"Preprocessing signal data...\")\n",
    "    signals_processed, onehot_labels, label_encoder, scaler = preprocess_signal_data(signals, labels)\n",
    "    \n",
    "    # Split data into training and testing sets (80/20 split)\n",
    "    X_train_signals, X_test_signals, y_train, y_test = train_test_split(\n",
    "        signals_processed, onehot_labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Convert training and testing signals to time-frequency images using parallel processing\n",
    "    logging.info(\"Converting training signals to time-frequency images using CWT in parallel...\")\n",
    "    X_train_images = create_image_dataset_parallel(X_train_signals)\n",
    "    logging.info(\"Converting testing signals to time-frequency images using CWT in parallel...\")\n",
    "    X_test_images = create_image_dataset_parallel(X_test_signals)\n",
    "    \n",
    "    # Normalize image pixel values to [0, 1]\n",
    "    X_train_images = X_train_images.astype('float32') / 255.0\n",
    "    X_test_images = X_test_images.astype('float32') / 255.0\n",
    "    \n",
    "    # Get input shape and number of classes for the model\n",
    "    input_shape = X_train_images.shape[1:]  # e.g., (224, 224, 1)\n",
    "    num_classes = y_train.shape[1]\n",
    "    \n",
    "    # Build the DCNN model\n",
    "    logging.info(\"Building the DCNN model...\")\n",
    "    model = build_dcnn_model(input_shape, num_classes)\n",
    "    \n",
    "    # Define callbacks\n",
    "    checkpoint = ModelCheckpoint(MODEL_SAVE_PATH, monitor='val_accuracy', verbose=1, \n",
    "                                 save_best_only=True, mode='max')\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_lr=1e-6)\n",
    "    callbacks_list = [checkpoint, earlystop, reduce_lr]\n",
    "    \n",
    "    # Train the model\n",
    "    logging.info(\"Starting model training...\")\n",
    "    history = model.fit(\n",
    "        X_train_images, y_train,\n",
    "        validation_split=0.1,\n",
    "        epochs=10,  # Increase epochs if you have more data and time for training\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks_list,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    logging.info(\"Evaluating the model on the test dataset...\")\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_images, y_test, verbose=1)\n",
    "    logging.info(f\"Test Loss: {test_loss:.4f}   Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Save the final model (best model saved by the checkpoint callback)\n",
    "    model.save(MODEL_SAVE_PATH)\n",
    "    logging.info(f\"Model saved to: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
